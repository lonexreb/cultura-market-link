{
  "workflow": {
    "id": "test-edge-cases",
    "name": "Edge Cases Workflow",
    "description": "Tests various edge cases and unusual node configurations",
    "nodes": [
      {
        "id": "empty-doc",
        "type": "document",
        "position": {"x": 100, "y": 100},
        "data": {
          "label": "Empty Document",
          "description": "Document with minimal text"
        },
        "config": {
          "text": "Short.",
          "chunk_size": 1000,
          "extract_entities": false
        }
      },
      {
        "id": "large-chunk-doc",
        "type": "document",
        "position": {"x": 100, "y": 250},
        "data": {
          "label": "Large Chunk Document",
          "description": "Document with very large chunk size"
        },
        "config": {
          "text": "This is a test document that will be processed with a very large chunk size to test edge cases in document processing. The chunk size is set much larger than the actual text to see how the system handles this scenario. This should result in a single chunk containing all the text.",
          "chunk_size": 9999,
          "extract_entities": true
        }
      },
      {
        "id": "extreme-temp-ai",
        "type": "claude4",
        "position": {"x": 400, "y": 100},
        "data": {
          "label": "Extreme Temperature AI",
          "description": "AI with edge case temperature settings"
        },
        "config": {
          "model": "claude-3-sonnet-20240229",
          "temperature": 0.0,
          "max_tokens": 1,
          "system_prompt": "Be extremely concise.",
          "user_prompt": "Summarize:"
        }
      },
      {
        "id": "high-temp-ai",
        "type": "groqllama",
        "position": {"x": 400, "y": 250},
        "data": {
          "label": "High Temperature AI",
          "description": "AI with maximum temperature"
        },
        "config": {
          "model": "llama3-70b-8192",
          "temperature": 1.0,
          "max_tokens": 50,
          "system_prompt": "Be creative and varied in your responses.",
          "user_prompt": "Create a creative response to:"
        }
      },
      {
        "id": "unicode-test",
        "type": "document",
        "position": {"x": 100, "y": 400},
        "data": {
          "label": "Unicode Test Document",
          "description": "Document with special characters and emojis"
        },
        "config": {
          "text": "üöÄ Testing Unicode support: h√©llo w√∂rld! ‰∏≠ÊñáÊµãËØï ÿßŸÑÿπÿ±ÿ®Ÿäÿ© —Ä—É—Å—Å–∫–∏–π üåü Special chars: ¬±‚àû‚âà‚â† ‚ô†‚ô£‚ô•‚ô¶ ‚Üê‚Üí‚Üë‚Üì ‚úì‚úó ¬ß¬∂‚Ä† Math: ‚àë‚àè‚à´‚àÇ‚àá Greek: Œ±Œ≤Œ≥Œ¥ŒµŒ∂Œ∑Œ∏ Currency: $‚Ç¨¬£¬•‚Çπ Misc: ¬©¬Æ‚Ñ¢‚Ñ†",
          "chunk_size": 100,
          "extract_entities": true
        }
      },
      {
        "id": "final-processor",
        "type": "gemini",
        "position": {"x": 700, "y": 250},
        "data": {
          "label": "Final Processor",
          "description": "Process all edge case results"
        },
        "config": {
          "model": "gemini-1.5-pro",
          "temperature": 0.5,
          "max_tokens": 200,
          "system_prompt": "You process various types of input data.",
          "user_prompt": "Process and summarize the following data:"
        }
      }
    ],
    "edges": [
      {
        "id": "edge-1",
        "source": "empty-doc",
        "target": "extreme-temp-ai"
      },
      {
        "id": "edge-2",
        "source": "large-chunk-doc",
        "target": "high-temp-ai"
      },
      {
        "id": "edge-3",
        "source": "extreme-temp-ai",
        "target": "final-processor"
      },
      {
        "id": "edge-4",
        "source": "high-temp-ai",
        "target": "final-processor"
      },
      {
        "id": "edge-5",
        "source": "unicode-test",
        "target": "final-processor"
      }
    ]
  },
  "debug": true
} 